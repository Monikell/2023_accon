#prepare example files
data(leafdata)
tf <- paste(tempdir(), "/", sep = "")
for (i in 1:7){
write.table(leafdata[[i]],paste(tf,names(leafdata)[i],sep=""),sep="\t")
}
(list.files(tf))
#prepare example files
data(leafdata)
unlink(list.files(tf))
source("~/.active-rstudio-document", echo=TRUE)
leafdata <- C:\Users\monik\Documents\C_Reserach\fieldwork_summer_2023\data\sla\arch\arch_all_renamed
students <- c("Steve", "Elsa", "Rich", "Courtney")
students
[students]
length(students)
kids <- data.frame(first_name = c("Steven", "Elsa", "Rich", "Courtney"),
age = c(13, 15, 14, 15))
kids
kids_xage <- data.frame(first_name = c("Steven", "Elsa", "Rich", "Courtney"),
age = c(13, 15, 14, 15, 16))
kids
kids$age
kids$age
kids$first_name
kids[1,2]
kids[1,]
kids[,2]
kids[,1]
kids[ ,1] # Isolate first column
kids[1, ]
kids2 <- data.frame(first_name = students,
age = c(13, 15, 14, 28))
kids2
# Select the name "Elsa"
kids$first_name[2]
kids
## what if we have a huge dataset?
kids$first_name[kids$first_name == "Elsa"]
kids$first_name == "Elsa"
#want this in the homework too!
kids$grades <- c(67, 99, 79, 84)
kids
hobby <- c("reading", "drawing", "horse back", "cars")
kids <- cbind(kids, hobby)
kids
ashley <- data.frame(who = "Ashley", age = 15, grade = 70, fun = "skate")
names(ashley)
names(kids)
rbind(kids, ashley)
ashley2 <- (who = "Ashley", age = 15, grade = 70, hobby = "skate")
names(ashley) <- names(kids)
ashley
rbind(kids, ashley)
kids
kids <- rbind(kids, ashley)
kids
# Loading packages
install.packages("dplyr")
library("dplyr")
? "full_join"
full_join(isotopes, long_lat)
# reading in TRY database data
my_data <- read.delim("29103.txt")
setwd("C:/Users/monik/Documents/reserach/fieldwork_summer_2023/data/2_processing/isotope_weight_values/try_requesteddata/merged")
# reading in TRY database data
my_data <- read.delim("29103.txt")
# checking out col. names
colnames(my_data)
# isolating rows with N/C and lat/long info
# 14 = carbon, 15 = Nitrogen, 59 = lat, 60 = long
data_isolate <- subset(my_data, DataID %in%
c (14, 15, 59, 60))
# checking info in the OriglName col.
unique(data_isolate$DataName)
## Trying nicks suggestion of subsetting
# Data id notes: # 14 = carbon, 15 = Nitrogen, 59 = lat, 60 = long
# Making individual dataframes based on teh values I want.
d_carbon <- subset(data_isolate, DataID %in% c (14))
d_nitrogen <- subset(data_isolate, DataID %in% c (15))
d_lat <- subset(data_isolate, DataID %in% c (59))
d_long <- subset(data_isolate, DataID %in% c (60))
# Chaning col. names, of "StandardValue"
colnames(d_carbon)[21] <- "%carbon"
colnames(d_nitrogen)[21] <- "%nitrogen"
colnames(d_lat)[21] <- "lat"
colnames(d_long)[21] <- "long"
# only columns I want, DataID (3), and StandardRate (21)
only_carbon <- d_carbon[,c(3,21)]
only_nitrogen <- d_nitrogen[,c(3,21)]
only_lat <- d_lat[,c(3,21)]
only_long <- d_long[,c(3,21)]
# Okay! Merging with original d_carbon data set, and
# the "only" datasets. That way have all the original info +
# the bits and pieces we want.
# merging with whole dataset = bad, puts values on everything.
test <- merge(data_isolate, only_carbon)
head(test)
View(test)
? "merge"
# trying to just merge the only data
# all things get a value and I don't think that is right.
# will write the data down into a file and go from there.
test <- merge(only_carbon, only_nitrogen)
View(test)
# writing data to look at it.
# seems okay, it looks like all carbon values have a nitrogen value
# make sense, getting carbon = getting nitrogen. try on lat and long now.
write.csv(data_isolate, file = "data_isolte.csv")
write.csv(test, file = "test.csv")
# merging only data now
# already merged N and C previous, just renaming them here.
isotopes <- test
# mering long and lats
long_lat <- merge(only_lat, only_long)
install.packages("dplyr")
library("dplyr")
? "full_join"
install.packages("dplyr")
full_join(isotopes, long_lat)
library("dplyr")
# Loading packages
install.packages("dplyr")
install.packages("dplyr")
full_join(isotopes, long_lat)
full_join(isotopes, long_lat)
install.packages("dplyr")
full_join(isotopes, long_lat)
isotopes %>% full_join(long_lat)
# attempting to repeated rows 75 - 78, joining isotopes and long_lat
View(isotopes)
View(long_lat)
merged_data <- isotopes %>% full_join(long_lat)
install.packages("tidyverse")
library("tidyverse")
merged_data <- isotopes %>% full_join(long_lat)
View(merged_data)
head(merged_data)
install.packages("dplyr")
install.packages("tidyverse")
library("dplyr")
library("tidyverse")
install.packages("tidyverse")
# Loading the TRY database informaiton
my_data <- read.delim("29103.txt")
# isolating rows with N/C and lat/long info
# 14 = carbon, 15 = Nitrogen, 59 = lat, 60 = long
data_isolate <- subset(my_data, DataID %in% c (14, 15, 59, 60))
# checking info in the OriglName col.
unique(data_isolate$DataName)
# Creating new vectors for each element fo interest to later be joined.
d_carbon <- subset(data_isolate, DataID %in% c (14))
d_nitrogen <- subset(data_isolate, DataID %in% c (15))
d_lat <- subset(data_isolate, DataID %in% c (59))
d_long <- subset(data_isolate, DataID %in% c (60))
# Updating the names of the "StandardValue" column to make it easier to find
# these values when they join back with the whole dataset.
colnames(d_carbon)[21] <- "%carbon"
colnames(d_nitrogen)[21] <- "%nitrogen"
colnames(d_lat)[21] <- "lat"
colnames(d_long)[21] <- "long"
# checking the column names to make sure things look good
head(d_carbob)
# checking the column names to make sure things look good
head(d_carbon)
# checking the column names to make sure things look good
View(d_carbon)
# Isolating columns we want "DatasetID" (3) "ObservationID" (8),
# and "StandardRate" (21)
# previously used "DatasetID" (3) only = bad.
only_carbon <- d_carbon[,c(3,8,21)]
View(only_carbon)
# Isolating columns we want "DatasetID" (3) "ObservationID" (8),
# and "StandardRate" (21)
# previously used "DatasetID" (3) only = bad.
only_carbon <- d_carbon[,c(3,8,21)]
only_nitrogen <- d_nitrogen[,c(3,8,21)]
only_lat <- d_lat[,c(3,8,21)]
only_long <- d_long[,c(3,8,21)]
# Merging isotope data
isotopes <- merge(only_nitrogen, only_carbon)
View(isotopes)
lat_long <- merge(only_lat, only_long)
View(lat_long)
iso_locations <- merge(isotopes, lat_long)
View(iso_locations)
? "merge"
iso_locations2 <- merge(isotopes, lat_long, all = TRUE)
# Merging isotope data, and lat and long data
isotopes <- merge(only_nitrogen, only_carbon, all = TRUE)
lat_long <- merge(only_lat, only_long, all = TRUE)
iso_locations2 <- merge(isotopes, lat_long, all = TRUE)
iso_locations <- merge(isotopes, lat_long, all = TRUE)
View(iso_locations)
# Merging
merged_data <- data_isolate %>% full_join(iso_locations)
remove(iso_locations2)
# Merging
merged_data <- merge(data_isolate, iso_locations)
# Merging
merged_data <- merge(data_isolate, iso_locations, all = TRUE)
View(merged_data)
write.csv("merged_data.csv")
write.csv(file = "merged_data.csv")
write.csv(merged_data, "merged_data.csv")
## Attempt to remove duplicates
test <- merged_data[!duplicated(merged_data$ObservationID)]
## Attempt to remove duplicates
test <- merged_data[!duplicated(merged_data[,2])]
test <- unique((merged_data[,2]))
View(test)
remove(test)
test <- merged_data[,duplicated(merged_data)]
View(test)
test <- merged_data[,!duplicated(merged_data)]
test <- merged_data[duplicated(merged_data), ]
View(test)
data <- read.csv(file = "merged_data.csv")
install.packages("tidyverse")
library("tidyverse")
# removing duplicates
data1 <- data[!duplicated(data$ObservationID), ]
View(data1)
colnames(data1)
# keeping the columns we want
relevant_data <- data1[c(2,3,8:10,31:34)]
View(relevant_data)
# keeping the columns we want
data_clean <- data1[c(2,3,8:10,31:34)]
remove(relevant_data)
# looking for unique values in latitude
unique_values <- unique(data_clean$lat)
print(unique_values)
